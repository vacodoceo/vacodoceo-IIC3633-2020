# Comentario "Collaborative Filtering for Implicit Feedback Datasets"

[![hackmd-github-sync-badge](https://hackmd.io/hnHchzhmTT2tGJpaFrPuyw/badge)](https://hackmd.io/hnHchzhmTT2tGJpaFrPuyw)

A modo general, me parece un paper muy útil para introducir el CF con feedbacks implícitos. Es interesante ver como se relaciona con los temas de los papers anteriores, haciendo mención a características del CF tales como que es *domain free* o que sufre de *cold start*. A su vez, también encuentro muy útil que se mencione las características del feedback implícito (que no es negativo, es ruidoso, indica seguridad pero no preferencia y que requiere tomar en cuenta otros factores como la disponibilidad/competencia del producto/servicio).

Con respecto a la propuesta en sí, esta es del 2008 y nace en un contexto en donde no había mayor investigación sobre CF con feedback implícitos. El modelo funciona similar a SVD, buscando encontrar vectores *"user-factor"* e *"item-factor"* de modo de obtener las preferencias mediante la ecuación ![](https://i.imgur.com/FEdrh3w.png). Estos vectores *"user-factor"* e *"item-factor"* se obtienen de forma similar a SVD, minimizando el error en preferencias. A diferencia de SVD, esta minimización se debe correr a lo largo de todos los pares *user-item*, lo que la hace extremadamente costosa con un método de gradiente y por lo mismo, se debió utilizar un método más complejo.

La implementación de este modelo me pareció muy ingeniosa, en especial porque se basa en SVD, un modelo exitoso pero imposible de replicar directamente, lo que significó repensar la forma de obtener los parámetros óptimos en la minimización de error. Mi único alcance reside en la definición del parámetro ![](https://i.imgur.com/DiUG0ee.png), el cual se define solo argumentando que fue el que mejor resultados entregó sin mencionar otros resultados o como puede afectar un cambio en tal parámetro.

Con respecto a la experimentación, entiendo que el *dataset* utilizado fue recolectado por los autores y bajo mi perspectiva es de muy buen tamaño, por lo que creo que es otro punto fuerte de la investigación. También se pueden ver buenos resultados en comparación a otros modelos anteriores. Me parece correcto el rango de *factors* en que se compararon resultados, mostrando que claramente un mayor número de *factors* conlleva a mejores resultados, sin embargo, esto también aumenta la complejidad de la optimización.

Extrañé ver como se incluia la competencia entre 2 productos/servicios en el análisis experimental. Creo que en estos casos puede residir la mayor parte de recomendaciones erróneas del modelo debido a lo complejo que es evaluarlos, y aún así no se les menciona en el análisis. El ejemplo que imagino es tener 2 shows al mismo tiempo, ambos similares pero teniendo uno de ellos mucho más concurrido que el otro. Acá sería interesante saber si el show con menos concurrencia está llevandose buenas recomendaciones a pesar de ser menos concurrido debido a la competencia.

Por último, también extrañe ver como se comportaba el modelo con otros tipos de *datasets*. Creo que el que se utilizó es de gran calidad, sin embargo, una de los puntos fuertes que se menciona sobre este tipo de modelos es que son *domain free*, por lo que estudiar, o al menos mencionar como se mantiene esa aseveración en un nuevo modelo también hubiera sido interesante.